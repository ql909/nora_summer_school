{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Objective\n",
        "\n",
        "In this Lab Session, students will learn to generate time series data using DopplGANger and TimeGAN, understand the application of GANs in time series generation, and compare their performance. Students will implement the code in Python within a Google Colab environment."
      ],
      "metadata": {
        "id": "lTv97pL1YzJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1: Environment Setup and Data Preparation**"
      ],
      "metadata": {
        "id": "4Wj2VTroY8dX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*step 1 Install Dependencies*\n",
        "\n",
        "Install required libraries in Colab, including `tensorflow, numpy, pandas, matplotlib`, and dependencies for `[DopplGANger]."
      ],
      "metadata": {
        "id": "a846_G7yY-hG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4TDyqo7Yr3t"
      },
      "outputs": [],
      "source": [
        "# please enter your codes here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*step 2 Prepare Dataset*\n",
        "\n",
        "Download the UCI Air Quality Dataset (https://archive.ics.uci.edu/ml/datasets/Air+Quality), which contains multivariate time series data (e.g., CO, NOx readings)."
      ],
      "metadata": {
        "id": "D21NTXIhZT6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# please enter your codes here"
      ],
      "metadata": {
        "id": "gac-wVdNZRAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*step 3 Data Preprocessing*\n",
        "\n",
        "*   Clean Data: Replace missing values (marked as -200) with NaN, fill using linear interpolation, and remove invalid records (e.g., rows with all NaN).\n",
        "*   Select Key Features: Choose key features for multivariate time series, e.g., CO(GT), NOx(GT), and temperature (T), to reduce complexity and focus on meaningful series.\n",
        "\n",
        "\n",
        "*   Normalize: Scale selected features to [-1, 1].\n",
        "*   Split Sequences: Segment data into time series windows (e.g., 24 steps) for model input.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W1guU-dbZ6MQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# please enter your codes here"
      ],
      "metadata": {
        "id": "SZPqaN3XbSe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "some hints for reference"
      ],
      "metadata": {
        "id": "yhNay1a4ycX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1: Data Preparation\n",
        "def download_and_prepare_air_quality_data(seq_len=24, selected_features=['CO(GT)', 'NOx(GT)', 'T']):\n",
        "    # Step 1: Download UCI Air Quality Dataset\n",
        "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip'\n",
        "    urllib.request.urlretrieve(url, 'AirQualityUCI.zip')\n",
        "\n",
        "    # Extract and load data\n",
        "    with zipfile.ZipFile('AirQualityUCI.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('air_quality')\n",
        "\n",
        "    data = pd.read_csv('air_quality/AirQualityUCI.csv', sep=';', decimal=',')\n",
        "\n",
        "    # Step 2: Clean Data\n",
        "    # Replace missing values (-200) with NaN\n",
        "\n",
        "    # Remove rows where all selected features are NaN\n",
        "\n",
        "    # Fill remaining NaN with linear interpolation\n",
        "\n",
        "\n",
        "    # Step 3: Select Key Features\n",
        "\n",
        "\n",
        "    # Step 4: Normalize Data\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    data_normalized = scaler.fit_transform(data)\n",
        "\n",
        "    # Step 5: Split Sequences\n"
      ],
      "metadata": {
        "id": "jvKCnJFKbK7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2: Implement and Train DopplGANger**\n",
        "\n"
      ],
      "metadata": {
        "id": "i9yWFbHUbWLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load DopplGANger Model:\n",
        "\n",
        "\n",
        "*   Clone the official DopplGANger GitHub repository (https://github.com/fjxmlzn/DopplGANger) in your environment.\n",
        "*   Install required dependencies (e.g., torch, ganite).\n",
        "\n",
        "*   Import DopplGANger’s core modules and understand its architecture (feature generator, time series generator, and discriminator)."
      ],
      "metadata": {
        "id": "UYKTLts-ciqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Set Hyperparameters: Configure hyperparameters, e.g.,\n",
        "time series length (24), feature dimensions (number of selected features), batch size, and epochs.\n",
        "\n",
        "2. Train Model: Train DopplGANger using the preprocessed air quality dataset, monitoring losses.\n",
        "\n",
        "3. Generate Data: Generate synthetic time series data with the trained DopplGANger and save results."
      ],
      "metadata": {
        "id": "Pa_Rr5iMdH2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# please enter your codes here"
      ],
      "metadata": {
        "id": "_4X8ycShd4fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3: Evaluate DopplGANger Generated Data**\n",
        "\n",
        "\n",
        "1）Visualize Generated Data: Plot original and DopplGANger-generated data, comparing feature trends.\n",
        "Quantitative Evaluation:\n",
        "\n",
        "    1. Autocorrelation Consistency: Compute the autocorrelation function (ACF) for real and synthetic data, comparing similarity across lags using mean squared error (MSE).\n",
        "\n",
        "    2. Dynamic Time Warping (DTW) Distance: Calculate DTW distance between real and synthetic sequences to assess shape similarity.\n",
        "\n",
        "    3. Periodicity Consistency: Use Fast Fourier Transform (FFT) to compute power spectral density (PSD) of real and synthetic data, comparing periodic patterns via KL divergence or cosine similarity.\n",
        "    4. Statistical Metrics: Compute mean and variance of generated vs. original data to evaluate basic statistical properties.\n",
        "\n",
        "2）ummarize Evaluation: Discuss DopplGANger’s generated data quality, focusing on time-series characteristics (autocorrelation, periodicity, shape similarity)."
      ],
      "metadata": {
        "id": "IGl5rqmueQZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*note: below the evaluation codes are for reference, you don't have to follow the codes.*"
      ],
      "metadata": {
        "id": "k2GqtP0Xyv2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3: Evaluation\n",
        "def evaluate_generated_data(real_data, synthetic_data, features, n_lags=10):\n",
        "    plt.figure(figsize=(15, 5 * len(features)))\n",
        "\n",
        "    # Visualization\n",
        "    for i, feature in enumerate(features):\n",
        "        plt.subplot(len(features), 2, i * 2 + 1)\n",
        "        plt.plot(real_data[0, :, i], label='Real')\n",
        "        plt.title(f'Real Data - {feature}')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(len(features), 2, i * 2 + 2)\n",
        "        plt.plot(synthetic_data[0, :, i], label='DopplGANger')\n",
        "        plt.title(f'DopplGANger - {feature}')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('dopplganger_data_comparison.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Quantitative Metrics\n",
        "    results = {}\n",
        "\n",
        "    for i, feature in enumerate(features):\n",
        "        real_seqs = real_data[:, :, i]\n",
        "        synth_seqs = synthetic_data[:, :, i]\n",
        "\n",
        "        # Autocorrelation Consistency (ACF with MSE)\n",
        "        real_acf = np.mean([acf(seq, nlags=n_lags, fft=True) for seq in real_seqs], axis=0)\n",
        "        synth_acf = np.mean([acf(seq, nlags=n_lags, fft=True) for seq in synth_seqs], axis=0)\n",
        "        acf_mse = mean_squared_error(real_acf, synth_acf)\n",
        "        results[f'{feature}_ACF_MSE'] = acf_mse\n",
        "\n",
        "        # Dynamic Time Warping (DTW) Distance\n",
        "        dtw_distances = []\n",
        "        for real_seq, synth_seq in zip(real_seqs[:10], synth_seqs[:10]):  # Limit for speed\n",
        "            distance, _ = fastdtw(real_seq, synth_seq)\n",
        "            dtw_distances.append(distance)\n",
        "        results[f'{feature}_DTW_Distance'] = np.mean(dtw_distances)\n",
        "\n",
        "        # Periodicity Consistency (PSD with Cosine Similarity and KL Divergence)\n",
        "        freqs, real_psd = signal.periodogram(real_seqs.flatten())\n",
        "        _, synth_psd = signal.periodogram(synth_seqs.flatten())\n",
        "        min_len = min(len(real_psd), len(synth_psd))\n",
        "        real_psd = real_psd[:min_len]\n",
        "        synth_psd = synth_psd[:min_len]\n",
        "        real_psd = real_psd / (np.sum(real_psd) + 1e-10)\n",
        "        synth_psd = synth_psd / (np.sum(synth_psd) + 1e-10)\n",
        "        psd_cosine = 1 - cosine(real_psd, synth_psd)\n",
        "        psd_kl = entropy(real_psd + 1e-10, synth_psd + 1e-10)\n",
        "        results[f'{feature}_PSD_Cosine'] = psd_cosine\n",
        "        results[f'{feature}_PSD_KL'] = psd_kl\n",
        "\n",
        "        # Statistical Metrics\n",
        "        results[f'{feature}_Mean_Real'] = np.mean(real_seqs)\n",
        "        results[f'{feature}_Mean_Synth'] = np.mean(synth_seqs)\n",
        "        results[f'{feature}_Variance_Real'] = np.var(real_seqs)\n",
        "        results[f'{feature}_Variance_Synth'] = np.var(synth_seqs)\n",
        "\n",
        "    for key, value in results.items():\n",
        "        print(f\"{key}: {value:.4f}\")\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "yz3DwblddYAM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
